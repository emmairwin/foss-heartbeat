{"body": "I've put together a first prototype for extracting the data from Telemetry. I think all the data we want is available from the public Telemetry aggregates. Prototype code is over at https://github.com/hannosch/normandy-telemetry. The data we can extract this way is at https://github.com/hannosch/normandy-telemetry/blob/master/exporter/data/histograms/UPTAKE_REMOTE_CONTENT_RESULT_1.json\r\n\r\nThe code is based on the Cerberus exporter code (part of telemetry alerts / https://docs.telemetry.mozilla.org/tools/alerts.html). My hope is that we could put the email alerting code into cerberus / medusa, so it lives in a central place for detecting and reporting on changes in Telemetry data. Cerberus has some nice features for detecting changes in the shape of histograms we might be able to re-use. Medusa is the web frontend and lives over at http://alerts.telemetry.mozilla.org/index.html#/detectors/1/alerts/?from=2017-07-15&to=2017-08-15&metrics-filter=\r\n\r\nSince it's possible to extract per-recipe data from the public telemetry API, we can probably get this data directly from telemetry on each recipe web page, without having to store it inside Normandy, but simply fetch it as needed.\r\n\r\nAnother possible approach is to use the exporter code and load all the data into Normandy. Than design new HTTP APIs to power per-recipe dashboards and act on the local data to provide the email alerting features.", "body_text": "I've put together a first prototype for extracting the data from Telemetry. I think all the data we want is available from the public Telemetry aggregates. Prototype code is over at https://github.com/hannosch/normandy-telemetry. The data we can extract this way is at https://github.com/hannosch/normandy-telemetry/blob/master/exporter/data/histograms/UPTAKE_REMOTE_CONTENT_RESULT_1.json\nThe code is based on the Cerberus exporter code (part of telemetry alerts / https://docs.telemetry.mozilla.org/tools/alerts.html). My hope is that we could put the email alerting code into cerberus / medusa, so it lives in a central place for detecting and reporting on changes in Telemetry data. Cerberus has some nice features for detecting changes in the shape of histograms we might be able to re-use. Medusa is the web frontend and lives over at http://alerts.telemetry.mozilla.org/index.html#/detectors/1/alerts/?from=2017-07-15&to=2017-08-15&metrics-filter=\nSince it's possible to extract per-recipe data from the public telemetry API, we can probably get this data directly from telemetry on each recipe web page, without having to store it inside Normandy, but simply fetch it as needed.\nAnother possible approach is to use the exporter code and load all the data into Normandy. Than design new HTTP APIs to power per-recipe dashboards and act on the local data to provide the email alerting features.", "url": "https://api.github.com/repos/mozilla/normandy/issues/comments/322754219", "created_at": "2017-08-16T12:25:44Z", "author_association": "NONE", "html_url": "https://github.com/mozilla/normandy/issues/951#issuecomment-322754219", "updated_at": "2017-08-16T12:25:44Z", "user": {"following_url": "https://api.github.com/users/hannosch/following{/other_user}", "events_url": "https://api.github.com/users/hannosch/events{/privacy}", "organizations_url": "https://api.github.com/users/hannosch/orgs", "url": "https://api.github.com/users/hannosch", "gists_url": "https://api.github.com/users/hannosch/gists{/gist_id}", "html_url": "https://github.com/hannosch", "subscriptions_url": "https://api.github.com/users/hannosch/subscriptions", "avatar_url": "https://avatars3.githubusercontent.com/u/483109?v=4", "repos_url": "https://api.github.com/users/hannosch/repos", "received_events_url": "https://api.github.com/users/hannosch/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/hannosch/starred{/owner}{/repo}", "site_admin": false, "login": "hannosch", "type": "User", "id": 483109, "followers_url": "https://api.github.com/users/hannosch/followers"}, "body_html": "<p>I've put together a first prototype for extracting the data from Telemetry. I think all the data we want is available from the public Telemetry aggregates. Prototype code is over at <a href=\"https://github.com/hannosch/normandy-telemetry\">https://github.com/hannosch/normandy-telemetry</a>. The data we can extract this way is at <a href=\"https://github.com/hannosch/normandy-telemetry/blob/master/exporter/data/histograms/UPTAKE_REMOTE_CONTENT_RESULT_1.json\">https://github.com/hannosch/normandy-telemetry/blob/master/exporter/data/histograms/UPTAKE_REMOTE_CONTENT_RESULT_1.json</a></p>\n<p>The code is based on the Cerberus exporter code (part of telemetry alerts / <a href=\"https://docs.telemetry.mozilla.org/tools/alerts.html\" rel=\"nofollow\">https://docs.telemetry.mozilla.org/tools/alerts.html</a>). My hope is that we could put the email alerting code into cerberus / medusa, so it lives in a central place for detecting and reporting on changes in Telemetry data. Cerberus has some nice features for detecting changes in the shape of histograms we might be able to re-use. Medusa is the web frontend and lives over at <a href=\"http://alerts.telemetry.mozilla.org/index.html#/detectors/1/alerts/?from=2017-07-15&amp;to=2017-08-15&amp;metrics-filter=\" rel=\"nofollow\">http://alerts.telemetry.mozilla.org/index.html#/detectors/1/alerts/?from=2017-07-15&amp;to=2017-08-15&amp;metrics-filter=</a></p>\n<p>Since it's possible to extract per-recipe data from the public telemetry API, we can probably get this data directly from telemetry on each recipe web page, without having to store it inside Normandy, but simply fetch it as needed.</p>\n<p>Another possible approach is to use the exporter code and load all the data into Normandy. Than design new HTTP APIs to power per-recipe dashboards and act on the local data to provide the email alerting features.</p>", "id": 322754219, "issue_url": "https://api.github.com/repos/mozilla/normandy/issues/951"}